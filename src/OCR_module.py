from datetime import datetime
import os

import cv2
from paddleocr import PaddleOCR


class OCRProcessor:
    def __init__(self, lang="ch", output_dir="OCR_output"):
        """
        åˆå§‹åŒ– OCR è™•ç†é¡åˆ¥
        """
        self.ocr = PaddleOCR(use_angle_cls=True, lang=lang)
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def flatten_coord(self, coord):
        """å±•å¹³å·¢ç‹€çµæ§‹çš„åº§æ¨™ï¼Œä¸¦è½‰æ›ç‚ºæµ®é»æ•¸"""
        while isinstance(coord, (list, tuple)):
            if not coord:
                return float("nan")
            coord = coord[0]
        try:
            return float(coord)
        except (TypeError, ValueError):
            print(f"è­¦å‘Š: ç„¡æ³•å°‡åº§æ¨™è½‰æ›ç‚ºæµ®é»æ•¸: {coord}, åŸå§‹è¼¸å…¥é¡å‹: {type(coord)}")
            return float("nan")

    def list_folders(self, directory):
        """å›å‚³è³‡æ–™å¤¾å…§æ‰€æœ‰çš„å­è³‡æ–™å¤¾åç¨±"""
        try:
            return [
                f
                for f in os.listdir(directory)
                if os.path.isdir(os.path.join(directory, f))
            ]
        except Exception as e:
            print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def process_images(self, img_dir, save_file=True):
        """
        OCR è™•ç†åœ–ç‰‡è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šåƒæ•¸æ±ºå®šæ˜¯å¦å„²å­˜çµæœã€‚

        :param img_dir: éœ€è¦é€²è¡Œ OCR çš„åœ–ç‰‡è³‡æ–™å¤¾
        :param save_file: æ˜¯å¦å°‡ OCR çµæœå„²å­˜ç‚º .txt æª”æ¡ˆï¼ˆé è¨­ Trueï¼‰
        :return: OCR è½‰æ›å¾Œçš„æ–‡å­—å…§å®¹ï¼ˆstringï¼‰
        """
        valid_extensions = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}
        image_files = [
            f
            for f in os.listdir(img_dir)
            if os.path.splitext(f)[1].lower() in valid_extensions
        ]

        print(f"ğŸ” æ‰¾åˆ°åœ–ç‰‡: {image_files}")
        all_output = ""

        for img_filename in image_files:
            img_path = os.path.join(img_dir, img_filename)
            print(f"ğŸ“· è™•ç†åœ–ç‰‡: {img_filename}")

            image = cv2.imread(img_path)
            if image is None:
                print(f"âš ï¸ è­¦å‘Š: è®€å– {img_path} å¤±æ•—ï¼Œè·³éæ­¤æª”æ¡ˆã€‚")
                continue

            height, width, _ = image.shape
            half_width = width / 2

            result = self.ocr.ocr(img_path, cls=True)
            messages = self._extract_messages(result, half_width)

            # çµ„åˆå°è©±å…§å®¹
            all_output += self._format_output(messages)

        if save_file:
            # ç”¢ç”Ÿæ™‚é–“è³‡è¨Šä¸¦å»ºç«‹æª”æ¡ˆåç¨±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_name = f"OCR_output_{timestamp}.txt"
            txt_filename = os.path.join(self.output_dir, output_name)

            with open(txt_filename, "w", encoding="utf-8") as f:
                f.write(all_output.strip())

            print(f"âœ… OCR çµæœå·²å„²å­˜è‡³ `{txt_filename}`")

        return all_output

    def _extract_messages(self, result, half_width):
        """å¾ OCR çµæœæå–å°è©±è¨Šæ¯"""
        messages = []
        if isinstance(result, list) and len(result) > 0 and isinstance(result[0], list):
            lines = result[0]
            for idx, line in enumerate(lines):
                bbox = line[0]
                line_info = line[1]
                if isinstance(line_info, tuple) and len(line_info) == 2:
                    text, confidence = line_info
                else:
                    text = "æ–‡å­—è§£æéŒ¯èª¤: line[1] æ ¼å¼ç•°å¸¸"
                    confidence = 0

                y_values = [self.flatten_coord(point[1]) for point in bbox]
                top = min(y_values)
                bottom = max(y_values)
                bbox_height = bottom - top
                x_values = [self.flatten_coord(point[0]) for point in bbox]
                center_x = sum(x_values) / len(x_values)

                speaker = "A" if center_x < half_width else "æˆ‘"

                if (
                    text != "å·²è®€"
                    and "ä¸‹åˆ" not in text
                    and "ä¸Šåˆ" not in text
                    and ":" not in text
                    and bbox_height > 10
                ):
                    messages.append((top, speaker, text.strip()))
                elif idx == 0 and text.startswith("<"):
                    if bbox_height > 5:
                        messages.append((top, speaker, text.strip()))
        else:
            print("è­¦å‘Š: OCR çµæœçµæ§‹ç•°å¸¸ï¼Œä¸æ˜¯é æœŸçš„åˆ—è¡¨")
        return messages

    def _format_output(self, messages):
        """æ ¼å¼åŒ–å°è©±å…§å®¹"""
        messages.sort(key=lambda x: x[0])
        paragraphs = []
        current_paragraph = []
        last_top = -999

        for i, message in enumerate(messages):
            top, speaker, text = message
            if i == 0 and text.startswith("<"):
                text = text[1:]
                messages[i] = (top, speaker, text)

            if not current_paragraph or (top - last_top) < 20:
                current_paragraph.append((top, speaker, text))
            else:
                paragraphs.append(current_paragraph)
                current_paragraph = [(top, speaker, text)]
            last_top = top
        if current_paragraph:
            paragraphs.append(current_paragraph)

        output_text = ""
        for paragraph in paragraphs:
            for message in paragraph:
                speaker = message[1]
                text = message[2]
                output_text += f"{speaker}: {text} "
            output_text += "\n"

        return output_text


# æ¸¬è©¦ä½¿ç”¨
if __name__ == "__main__":
    ocr_processor = OCRProcessor(lang="ch", output_dir="OCR_output")
    img_dir = "input_dir"
    #ocr_processor.process_images(img_dir, "output.txt")
    conversation = ocr_processor.process_images(img_dir)
    print(conversation)
